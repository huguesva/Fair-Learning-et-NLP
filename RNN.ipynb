{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labels:\n",
    "Titles = np.ravel(pickle.load(open('Titles.pkl','rb')))\n",
    "dico_titles = pickle.load(open('title_prop.pkl','rb'))\n",
    "\n",
    "#Fasttext embeddings:\n",
    "X_fasttext = pickle.load(open('X_fasttext_ind.pkl','rb'))\n",
    "X_fasttext_nogen = pickle.load(open('X_fasttext_nogen_ind.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing, tensorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_utils.TensorDataset(X_fasttext, Titles)\n",
    "train_loader = data_utils.DataLoader(train, batch_size = 10, shuffle = True)\n",
    "\n",
    "trainnogen = data_utils.TensorDataset(X_fasttext_nogen, Titles)\n",
    "train_loader_nogen = data_utils.DataLoader(train_nogen, batch_size = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bidirectional = True):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.gru = nn.GRU(input_size, hidden_size, bidirectional = bidirectional)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        output, hidden = self.gru(inputs.view(1, 1, self.input_size), hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(1 + int(self.bidirectional), 1, self.hidden_size),\n",
    "          torch.zeros(1 + int(self.bidirectional), 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder(nn.Module):\n",
    "  \n",
    "    def __init__(self, hidden_size, output_size, vocab_size):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.attn = nn.Linear(hidden_size + output_size, 1)\n",
    "        self.gru = nn.GRU(hidden_size + vocab_size, output_size) #if we are using embedding hidden_size should be added with embedding of vocab size\n",
    "        self.final = nn.Linear(output_size, vocab_size)\n",
    "  \n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(1, 1, self.output_size),\n",
    "          torch.zeros(1, 1, self.output_size))\n",
    "  \n",
    "    def forward(self, decoder_hidden, encoder_outputs, input):\n",
    "\n",
    "        weights = []\n",
    "        for i in range(len(encoder_outputs)):\n",
    "            weights.append(self.attn(torch.cat((decoder_hidden[0][0], \n",
    "                                              encoder_outputs[i]), dim = 1)))\n",
    "        normalized_weights = F.softmax(torch.cat(weights, 1), 1)\n",
    "\n",
    "        attn_applied = torch.bmm(normalized_weights.unsqueeze(1),\n",
    "                                 encoder_outputs.view(1, -1, self.hidden_size))\n",
    "\n",
    "        input_lstm = torch.cat((attn_applied[0], input[0]), dim = 1)\n",
    "\n",
    "        output, hidden = self.gru(input_lstm.unsqueeze(0), decoder_hidden)\n",
    "\n",
    "        output = self.final(output[0])\n",
    "\n",
    "        return output, hidden, normalized_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bio(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[0]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    else:\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  \n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            \n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all(inputs, targets, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        print(train_bio(inputs[i], targets[i], encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=max_length))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
